{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:47.537561Z",
     "iopub.status.busy": "2025-01-22T12:03:47.537242Z",
     "iopub.status.idle": "2025-01-22T12:03:47.542011Z",
     "shell.execute_reply": "2025-01-22T12:03:47.540896Z",
     "shell.execute_reply.started": "2025-01-22T12:03:47.537538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:47.543561Z",
     "iopub.status.busy": "2025-01-22T12:03:47.543267Z",
     "iopub.status.idle": "2025-01-22T12:03:50.820191Z",
     "shell.execute_reply": "2025-01-22T12:03:50.819447Z",
     "shell.execute_reply.started": "2025-01-22T12:03:47.543527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/cleaned-dataset/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:50.821868Z",
     "iopub.status.busy": "2025-01-22T12:03:50.821651Z",
     "iopub.status.idle": "2025-01-22T12:03:50.853453Z",
     "shell.execute_reply": "2025-01-22T12:03:50.852711Z",
     "shell.execute_reply.started": "2025-01-22T12:03:50.821850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:50.854879Z",
     "iopub.status.busy": "2025-01-22T12:03:50.854671Z",
     "iopub.status.idle": "2025-01-22T12:03:50.874415Z",
     "shell.execute_reply": "2025-01-22T12:03:50.873534Z",
     "shell.execute_reply.started": "2025-01-22T12:03:50.854861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_texts = train_texts.astype(str)\n",
    "test_texts = test_texts.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:50.875555Z",
     "iopub.status.busy": "2025-01-22T12:03:50.875321Z",
     "iopub.status.idle": "2025-01-22T12:03:52.278406Z",
     "shell.execute_reply": "2025-01-22T12:03:52.277481Z",
     "shell.execute_reply.started": "2025-01-22T12:03:50.875535Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd276bd0e57b4e83be28da53867a8b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3424dafe4b274ae990da764cf8fab30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63cfe066aa74008ae5d5d07beb17130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccb135b78b0442d81afcefdf1cbc553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:03:52.279784Z",
     "iopub.status.busy": "2025-01-22T12:03:52.279460Z",
     "iopub.status.idle": "2025-01-22T12:23:29.727478Z",
     "shell.execute_reply": "2025-01-22T12:23:29.726747Z",
     "shell.execute_reply.started": "2025-01-22T12:03:52.279752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Tokenize the input texts\n",
    "def tokenize_texts(texts, tokenizer, max_length=128, device='cpu'):\n",
    "    encodings = tokenizer(\n",
    "        list(texts),  # Convert Series to list\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )\n",
    "    # Move tensors to the specified device (e.g., GPU if available)\n",
    "    encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "    return encodings\n",
    "\n",
    "# Specify the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Tokenize texts and move them to GPU if available\n",
    "train_encodings = tokenize_texts(train_texts, tokenizer, device=device)\n",
    "test_encodings = tokenize_texts(test_texts, tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:29.729725Z",
     "iopub.status.busy": "2025-01-22T12:23:29.729482Z",
     "iopub.status.idle": "2025-01-22T12:23:29.738281Z",
     "shell.execute_reply": "2025-01-22T12:23:29.737545Z",
     "shell.execute_reply.started": "2025-01-22T12:23:29.729704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Convert labels to tensors\n",
    "train_labels = torch.tensor(train_labels.values)\n",
    "test_labels = torch.tensor(test_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:29.739838Z",
     "iopub.status.busy": "2025-01-22T12:23:29.739559Z",
     "iopub.status.idle": "2025-01-22T12:23:29.750277Z",
     "shell.execute_reply": "2025-01-22T12:23:29.749418Z",
     "shell.execute_reply.started": "2025-01-22T12:23:29.739817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "test_dataset = NewsDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:29.751189Z",
     "iopub.status.busy": "2025-01-22T12:23:29.750972Z",
     "iopub.status.idle": "2025-01-22T12:23:32.189958Z",
     "shell.execute_reply": "2025-01-22T12:23:32.189098Z",
     "shell.execute_reply.started": "2025-01-22T12:23:29.751146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dacf5bd77f24db8a3e0558b1bafe090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:32.191352Z",
     "iopub.status.busy": "2025-01-22T12:23:32.191024Z",
     "iopub.status.idle": "2025-01-22T12:23:32.358662Z",
     "shell.execute_reply": "2025-01-22T12:23:32.357967Z",
     "shell.execute_reply.started": "2025-01-22T12:23:32.191322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 7: Define the DataLoader, optimizer, and loss function\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:32.359558Z",
     "iopub.status.busy": "2025-01-22T12:23:32.359339Z",
     "iopub.status.idle": "2025-01-22T12:23:32.365078Z",
     "shell.execute_reply": "2025-01-22T12:23:32.364181Z",
     "shell.execute_reply.started": "2025-01-22T12:23:32.359539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Encodings Shape: torch.Size([162708, 128])\n",
      "Testing Encodings Shape: torch.Size([40677, 128])\n",
      "Training Labels Shape: torch.Size([162708])\n",
      "Testing Labels Shape: torch.Size([40677])\n"
     ]
    }
   ],
   "source": [
    "# Output shapes for verification\n",
    "print(\"Training Encodings Shape:\", train_encodings['input_ids'].shape)\n",
    "print(\"Testing Encodings Shape:\", test_encodings['input_ids'].shape)\n",
    "print(\"Training Labels Shape:\", train_labels.shape)\n",
    "print(\"Testing Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:23:32.366158Z",
     "iopub.status.busy": "2025-01-22T12:23:32.365919Z",
     "iopub.status.idle": "2025-01-22T12:23:33.168950Z",
     "shell.execute_reply": "2025-01-22T12:23:33.168036Z",
     "shell.execute_reply.started": "2025-01-22T12:23:32.366139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized inputs and labels saved for BERT.\n"
     ]
    }
   ],
   "source": [
    "# Save the tokenized data (optional, for future use)\n",
    "torch.save((train_encodings, train_labels), 'train_data.pt')\n",
    "torch.save((test_encodings, test_labels), 'test_data.pt')\n",
    "print(\"Tokenized inputs and labels saved for BERT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:28:12.147290Z",
     "iopub.status.busy": "2025-01-22T12:28:12.146965Z",
     "iopub.status.idle": "2025-01-22T12:28:12.153747Z",
     "shell.execute_reply": "2025-01-22T12:28:12.152899Z",
     "shell.execute_reply.started": "2025-01-22T12:28:12.147265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, loss_fn, device, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                predictions = torch.argmax(outputs.logits, dim=1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T12:28:22.563957Z",
     "iopub.status.busy": "2025-01-22T12:28:22.563631Z",
     "iopub.status.idle": "2025-01-22T14:05:08.004090Z",
     "shell.execute_reply": "2025-01-22T14:05:08.003260Z",
     "shell.execute_reply.started": "2025-01-22T12:28:22.563928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.2458\n",
      "Epoch 1, Validation Accuracy: 0.8756\n",
      "Epoch 2, Training Loss: 0.1911\n",
      "Epoch 2, Validation Accuracy: 0.8781\n",
      "Epoch 3, Training Loss: 0.1705\n",
      "Epoch 3, Validation Accuracy: 0.8755\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, optimizer, scheduler, loss_fn, device, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:05:08.005529Z",
     "iopub.status.busy": "2025-01-22T14:05:08.005207Z",
     "iopub.status.idle": "2025-01-22T14:05:08.570400Z",
     "shell.execute_reply": "2025-01-22T14:05:08.569662Z",
     "shell.execute_reply.started": "2025-01-22T14:05:08.005505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(\"bert_finetuned\")\n",
    "tokenizer.save_pretrained(\"bert_finetuned\")\n",
    "print(\"Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T14:05:08.571808Z",
     "iopub.status.busy": "2025-01-22T14:05:08.571511Z",
     "iopub.status.idle": "2025-01-22T14:05:08.577433Z",
     "shell.execute_reply": "2025-01-22T14:05:08.576695Z",
     "shell.execute_reply.started": "2025-01-22T14:05:08.571781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Encodings Shape: torch.Size([162708, 128])\n",
      "Testing Encodings Shape: torch.Size([40677, 128])\n",
      "Training Labels Shape: torch.Size([162708])\n",
      "Testing Labels Shape: torch.Size([40677])\n"
     ]
    }
   ],
   "source": [
    "# Output shapes for verification\n",
    "print(\"Training Encodings Shape:\", train_encodings['input_ids'].shape)\n",
    "print(\"Testing Encodings Shape:\", test_encodings['input_ids'].shape)\n",
    "print(\"Training Labels Shape:\", train_labels.shape)\n",
    "print(\"Testing Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6511782,
     "sourceId": 10521478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
